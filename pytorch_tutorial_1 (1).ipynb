{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "pytorch_tutorial_1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnm67KGYZolC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZq7BxLzZolG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Introduction to PyTorch\n",
        "***********************\n",
        "\n",
        "Introduction to Torch's tensor library\n",
        "======================================\n",
        "\n",
        "All of deep learning is computations on tensors, which are\n",
        "generalizations of a matrix that can be indexed in more than 2\n",
        "dimensions. We will see exactly what this means in-depth later. First,\n",
        "lets look what we can do with tensors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6udHsh2FZolH",
        "colab_type": "code",
        "outputId": "8b8cf750-7c07-469c-eb81-8e705e8caccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0a6a90ced0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN5xV5b2ZolK",
        "colab_type": "text"
      },
      "source": [
        "## Creating Tensors\n",
        "\n",
        "\n",
        "### Tensors can be created from Python lists with the torch.Tensor() function.\n",
        "\n",
        "\n",
        "![alt text](https://www.kdnuggets.com/wp-content/uploads/tensor-examples.jpg)\n",
        "\n",
        "\n",
        "### A note on terminology:\n",
        " * \"tensor\"  refers to any torch.Tensor object.  \n",
        " * Matrices and vectors are special cases of torch.Tensors.\n",
        " * 3D tensors,explicitly use the term \"3D tensor\".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebt9ISHJZolK",
        "colab_type": "code",
        "outputId": "5a4c0f30-3c65-4957-b56c-529a9a68890d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# torch.tensor(data) creates a torch.Tensor object with the given data.\n",
        "V_data = [1., 2., 3.]\n",
        "V = torch.tensor(V_data)\n",
        "\n",
        "V"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tytAu36kad7Z",
        "colab_type": "code",
        "outputId": "deb20b3d-09a9-437f-89d9-5122933152ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Creates a matrix\n",
        "M_data = [[1., 2., 3.], [4., 5., 6]]\n",
        "M = torch.tensor(M_data)\n",
        "M"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXpjdIqYaeHS",
        "colab_type": "code",
        "outputId": "def3dffb-959e-421c-bb08-dbfcdf837d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Create a 3D tensor of size 2x2x2.\n",
        "T_data = [[[1., 2.], [3., 4.]],\n",
        "          [[5., 6.], [7., 8.]]]\n",
        "T = torch.tensor(T_data)\n",
        "T"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 2.],\n",
              "         [3., 4.]],\n",
              "\n",
              "        [[5., 6.],\n",
              "         [7., 8.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4udai7Bc57W",
        "colab_type": "text"
      },
      "source": [
        "## Inexing the pytorch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAndL5ZsZolO",
        "colab_type": "code",
        "outputId": "b26fbeb9-90b7-4038-857b-46aaab9d5dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Index into V and get a scalar (0 dimensional tensor)\n",
        "V[0]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o1TlSyNdFSJ",
        "colab_type": "code",
        "outputId": "17212a91-e27d-430a-8924-742f4ef53fae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get a Python number from it\n",
        "V[0].item()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaQGKB1pdLuy",
        "colab_type": "code",
        "outputId": "1372d4f0-86ba-40d5-b5d6-685336785f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Index into M and get a vector\n",
        "M[0]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26SIkTQJdVN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## M[0].item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEf8u7T3dP7R",
        "colab_type": "code",
        "outputId": "72801baf-5e48-46c8-c336-6ee572d23511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Index into T and get a matrix\n",
        "T[0]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WKzQ_2QZolQ",
        "colab_type": "text"
      },
      "source": [
        "### Tensors of other data type is possible\n",
        "### Defaul is Float\n",
        "\n",
        "![alt text](https://allenlu2007.files.wordpress.com/2018/11/newimage.png?w=598&h=254)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEuEurAzd8V0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "? torch.tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljIqUq7-fIXM",
        "colab_type": "code",
        "outputId": "99021926-fb23-4418-e371-07e4b7a25463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "M.type()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSfpCDYmZolR",
        "colab_type": "text"
      },
      "source": [
        "### create a tensor with random data and the supplied dimensionality with torch.randn()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQd5EF1WZolT",
        "colab_type": "code",
        "outputId": "aed79dd5-ea7d-4417-ad82-0828f196766e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "x = torch.randn((3, 4, 5))\n",
        "\n",
        "x"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.5256, -0.7502, -0.6540, -1.6095, -0.1002],\n",
              "         [-0.6092, -0.9798, -1.6091, -0.7121,  0.3037],\n",
              "         [-0.7773, -0.2515, -0.2223,  1.6871,  0.2284],\n",
              "         [ 0.4676, -0.6970, -1.1608,  0.6995,  0.1991]],\n",
              "\n",
              "        [[ 0.8657,  0.2444, -0.6629,  0.8073,  1.1017],\n",
              "         [-0.1759, -2.2456, -1.4465,  0.0612, -0.6177],\n",
              "         [-0.7981, -0.1316,  1.8793, -0.0721,  0.1578],\n",
              "         [-0.7735,  0.1991,  0.0457,  0.1530, -0.4757]],\n",
              "\n",
              "        [[-0.1110,  0.2927, -0.1578, -0.0288,  0.4533],\n",
              "         [ 1.1422,  0.2486, -1.7754, -0.0255, -1.0233],\n",
              "         [-0.5962, -1.0055,  0.4285,  1.4761, -1.7869],\n",
              "         [ 1.6103, -0.7040, -0.1853, -0.9962, -0.8313]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrSWZmixZolV",
        "colab_type": "text"
      },
      "source": [
        "# Operations with Tensors\n",
        "\n",
        "\n",
        "### Addition \n",
        "# +\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RUP8akLZolV",
        "colab_type": "code",
        "outputId": "e55fd156-154e-41c8-f40b-90df7e7f3cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([1., 2., 3.])\n",
        "y = torch.tensor([4., 5., 6.])\n",
        "z = x + y\n",
        "\n",
        "z"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5., 7., 9.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSqDpi3YZolX",
        "colab_type": "text"
      },
      "source": [
        "## concatenates\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj1mAuQhZolY",
        "colab_type": "code",
        "outputId": "e9d7a2f0-803d-43ec-dd81-873222832828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# By default, it concatenates along the first axis (concatenates rows)\n",
        "x_1 = torch.randn(2, 5)\n",
        "print(x_1,'\\n')\n",
        "y_1 = torch.randn(3, 5)\n",
        "print(y_1,'\\n')\n",
        "z_1 = torch.cat([x_1, y_1])\n",
        "\n",
        "z_1"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.8029,  0.2366,  0.2857,  0.6898, -0.6331],\n",
            "        [ 0.8795, -0.6842,  0.4533,  0.2912, -0.8317]]) \n",
            "\n",
            "tensor([[-0.5525,  0.6355, -0.3968, -0.6571, -1.6428],\n",
            "        [ 0.9803, -0.0421, -0.8206,  0.3133, -1.1352],\n",
            "        [ 0.3773, -0.2824, -2.5667, -1.4303,  0.5009]]) \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8029,  0.2366,  0.2857,  0.6898, -0.6331],\n",
              "        [ 0.8795, -0.6842,  0.4533,  0.2912, -0.8317],\n",
              "        [-0.5525,  0.6355, -0.3968, -0.6571, -1.6428],\n",
              "        [ 0.9803, -0.0421, -0.8206,  0.3133, -1.1352],\n",
              "        [ 0.3773, -0.2824, -2.5667, -1.4303,  0.5009]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnGBrM4tf3ta",
        "colab_type": "code",
        "outputId": "f94d346e-0926-46f4-a0ce-bec2305b49d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Concatenate columns:\n",
        "x_2 = torch.randn(2, 3)\n",
        "print(x_2,'\\n')\n",
        "y_2 = torch.randn(2, 5)\n",
        "print(y_2,'\\n')\n",
        "# second arg specifies which axis to concat along\n",
        "z_2 = torch.cat([x_2, y_2], 1)\n",
        "\n",
        "z_2"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5438, -0.4057,  1.1341],\n",
            "        [-1.1115,  0.3501, -0.7703]]) \n",
            "\n",
            "tensor([[-0.1473,  0.6272,  1.0935,  0.0939,  1.2381],\n",
            "        [-1.3459,  0.5119, -0.6933, -0.1668, -0.9999]]) \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5438, -0.4057,  1.1341, -0.1473,  0.6272,  1.0935,  0.0939,  1.2381],\n",
              "        [-1.1115,  0.3501, -0.7703, -1.3459,  0.5119, -0.6933, -0.1668, -0.9999]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LegUMql1gZ-T",
        "colab_type": "text"
      },
      "source": [
        "## what if tensors are not copatible ??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWijDXOAf34D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.cat([x_1, x_2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVQdD47VZola",
        "colab_type": "text"
      },
      "source": [
        "## Reshaping Tensors\n",
        "\n",
        "\n",
        "### We can use  .view() method to reshape a tensor. \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "This method receives heavy use, because many neural network components expect their inputs to have a certain shape. Often you will need to reshape before passing your data  to the component.\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1gPvQ_dZolb",
        "colab_type": "code",
        "outputId": "02432fbb-d2a4-4361-837d-4e50399470ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "x = torch.randn(2, 3, 2)\n",
        "\n",
        "x"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.6476,  0.8098],\n",
              "         [ 0.0554,  1.1340],\n",
              "         [-0.5326,  0.6592]],\n",
              "\n",
              "        [[-1.5964, -0.3769],\n",
              "         [-3.1020, -0.0995],\n",
              "         [-0.7213,  1.2708]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqs25jzmg6aL",
        "colab_type": "code",
        "outputId": "c09a0f05-da26-4c09-c24b-3378cd8b8439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x.view(2, 6)  # Reshape to 2 rows, 12 columns"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.6476,  0.8098,  0.0554,  1.1340, -0.5326,  0.6592],\n",
              "        [-1.5964, -0.3769, -3.1020, -0.0995, -0.7213,  1.2708]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvu01wK5g6ge",
        "colab_type": "code",
        "outputId": "e740f46c-fed9-477a-c0bd-82e42a41b292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Same as above.  If one of the dimensions is -1, its size can be inferred\n",
        "x.view(2, -1)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.6476,  0.8098,  0.0554,  1.1340, -0.5326,  0.6592],\n",
              "        [-1.5964, -0.3769, -3.1020, -0.0995, -0.7213,  1.2708]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5we4VOqFhlWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBojnQraZole",
        "colab_type": "text"
      },
      "source": [
        "Computation Graphs and Automatic Differentiation\n",
        "================================================\n",
        "\n",
        "* A computation graph is simply a specification of how your data is combined to give you the output.\n",
        "*  It allows automatic claculation of gradient in  back propagation gradients .\n",
        "\n",
        "\n",
        "## What is stored in the torch.Tensor objects ??\n",
        "* data \n",
        "* shape\n",
        "* other.. \n",
        "\n",
        "\n",
        "### If ``requires_grad=True``, the Tensor object keeps track of how it was created. Lets see it in action.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z07FtKK8Zolf",
        "colab_type": "code",
        "outputId": "16096e7d-d7bd-4418-e8d1-c33a31514c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Tensor factory methods have a ``requires_grad`` flag\n",
        "x = torch.tensor([1., 2., 3], requires_grad=True)\n",
        "\n",
        "# With requires_grad=True, you can still do all the operations you previously\n",
        "# could\n",
        "y = torch.tensor([4., 5., 6], requires_grad=True)\n",
        "z = x + y\n",
        "z    #this time z has something extra"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5., 7., 9.], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgJOB4sjjUY8",
        "colab_type": "code",
        "outputId": "63b2d795-cad7-4a84-fd07-a03858780b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z.grad_fn"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AddBackward0 at 0x7f0a1ed9ab38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtK1dcKbZolh",
        "colab_type": "text"
      },
      "source": [
        "### Tensors know what created them.\n",
        "\n",
        "z knows that it wasn't read in from a file, it wasn't the result of a multiplication or exponential or\n",
        "whatever. And if you keep following z.grad_fn, you will find yourself at\n",
        "x and y.\n",
        "\n",
        "### But how does that help us compute a gradient?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHIVkkqlZolh",
        "colab_type": "code",
        "outputId": "006cebbf-b18a-45ac-9682-156a941839a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Lets sum up all the entries in z\n",
        "s = z.sum()\n",
        "print(s)\n",
        "\n",
        "s.grad_fn"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(21., grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SumBackward0 at 0x7f0a1ed950f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ifu4ZrvWZolj",
        "colab_type": "text"
      },
      "source": [
        "So now, what is the derivative of this sum with respect to the first\n",
        "component of x? In math, we want\n",
        "\n",
        "\\begin{align}\\frac{\\partial s}{\\partial x_0}\\end{align}\n",
        "\n",
        "\n",
        "\n",
        "Well, s knows that it was created as a sum of the tensor z. z knows that it was the sum x + y. So\n",
        "\n",
        "\\begin{align}s = \\overbrace{x_0 + y_0}^\\text{$z_0$} + \\overbrace{x_1 + y_1}^\\text{$z_1$} + \\overbrace{x_2 + y_2}^\\text{$z_2$}\\end{align}\n",
        "\n",
        "And so s contains enough information to determine that the derivative we want is 1!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaelKq22Zolk",
        "colab_type": "text"
      },
      "source": [
        "## opt.zero_grad(), loss.backward(), opt.step()\n",
        "\n",
        "\n",
        "### zero_grad \n",
        "clears old gradients from the last step (otherwise youâ€™d just accumulate the gradients from all loss.backward() calls).\n",
        "\n",
        "### loss.backward() \n",
        "computes the derivative of the loss w.r.t. the parameters (or anything requiring gradients) using backpropagation.\n",
        "\n",
        "### opt.step()\n",
        "causes the optimizer to take a step based on the gradients of the parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKpEEP6MZolk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d426455-315e-4256-c47f-6cc0ac482e5d"
      },
      "source": [
        "# calling .backward() on any variable will run backprop, starting from it.\n",
        "s.backward()\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vKje6dpZoln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "44aabbd2-28b2-4c3f-ac1a-a614e6e6efd1"
      },
      "source": [
        "x = torch.randn(2, 2)\n",
        "y = torch.randn(2, 2)\n",
        "# By default, user created Tensors have ``requires_grad=False``\n",
        "print(x.requires_grad, y.requires_grad)\n",
        "z = x + y\n",
        "# So you can't backprop through z\n",
        "print(z.grad_fn)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False False\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDGzAgvhmBsK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9af3b5e-d4c1-4cda-8457-393dc75dea24"
      },
      "source": [
        "# ``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\n",
        "# flag in-place. The input flag defaults to ``True`` if not given.\n",
        "x = x.requires_grad_()\n",
        "y = y.requires_grad_()\n",
        "# z contains enough information to compute gradients, as we saw above\n",
        "z = x + y\n",
        "print(z.grad_fn)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7f0a1ed95fd0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp4EtZF1mJZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "78c4cb3a-9e19-477d-ab86-aab27a7209e3"
      },
      "source": [
        "# If any input to an operation has ``requires_grad=True``, so will the output\n",
        "print(z.requires_grad)\n",
        "\n",
        "# Now z has the computation history that relates itself to x and y\n",
        "# Can we just take its values, and **detach** it from its history?\n",
        "new_z = z.detach()\n",
        "\n",
        "# ... does new_z have information to backprop to x and y?\n",
        "# NO!\n",
        "print(new_z.grad_fn)\n",
        "# And how could it? ``z.detach()`` returns a tensor that shares the same storage\n",
        "# as ``z``, but with the computation history forgotten. It doesn't know anything\n",
        "# about how it was computed.\n",
        "# In essence, we have broken the Tensor away from its past history"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voN_4a_xZolq",
        "colab_type": "text"
      },
      "source": [
        "You can also stop autograd from tracking history on Tensors\n",
        "with ``.requires_grad``=True by wrapping the code block in\n",
        "``with torch.no_grad():``\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mADKh33DZolr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2eb09718-e807-461a-9de6-79b5053a67af"
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "\tprint((x ** 2).requires_grad)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}